# AI Red Team Casebook

A documentation casebook by **Jane Choi**, capturing cognitive, narrative, and emotional vulnerabilities observed in large language models (LLMs) through adversarial testing and behavioral prompt design.

---

## ğŸ“ Case Logs

- [Case 01: System Collapse](cases/01-system-collapse.md)  
- [Case 02: ğŸ”’ Narrative Overwrite](cases/02-narrative-overwrite.md)  
- [Case 03: Empathic Hallucination](cases/03-empathic-hallucination.md)  
- [Case 04: Emotional Seduction Loop](cases/04-emotional-seduction-loop.md)  
- [Case 05: ğŸ”’ Live Breakdown + Fluency Overwrite](cases/05-live-breakdown-fluency-overwrite.md) _(Locked â€” available by request)_  
- [Case 06: ğŸ”’ Mirror Effect â€” Tesla Dream Reinforcement](cases/06-mirror-effect-tesla-dream.md)

ğŸ“„ [Recruiter Summary â†’ /reports/hire-me.md](./reports/hire-me.md)

---

## ğŸ§  Behavioral Risk Index (Live)

This repo includes a full inline vulnerability taxonomy covering five critical behavioral risks identified in red team cases:

- ğŸª Mirror Effect â€“ emotional tone/belief mirroring  
- ğŸ”® Empathic Hallucination â€“ poetic affirmation of false beliefs  
- ğŸ§  Fluency-Induced Trust â€“ polished language, unverified claims  
- ğŸ§© Narrative Drift â€“ subtle transformation across multi-turn chats  
- âš ï¸ Authority Simulation â€“ users overtrust confident system tone  

ğŸ“˜ [View full index â†’](theory/index.md)
