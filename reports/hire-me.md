# 👋 Hello, I’m Jane Choi — Cognitive Red Team Analyst for LLMs

This repository documents **high-risk behavioral patterns** observed in large language models (LLMs) during adversarial prompt testing.  
It focuses on **cognitive, emotional, and narrative vulnerabilities** that bypass traditional safety filters.

---

## 🧠 My Focus Areas

I specialize in:

- 🪞 **Mirror Effect** — When models reflect emotional tone or belief without factual grounding  
- 🔮 **Empathic AI Hallucination** — When emotionally resonant responses affirm false or unverifiable claims  
- 🧠 **Fluency-Induced Trust Loops** — When output tone, polish, and coherence override skepticism  
- 🧩 **Narrative Overwrite** — When model outputs reshape user memory, beliefs, or intent

These aren’t just hallucinations — they’re **trust failures** in human-model interaction.

---

## 📂 Casebook Highlights

| Case # | Title | Risk Types | Status |
|--------|-------|------------|--------|
| 01 | System Collapse via Context Drift | Context Overflow, Memory Decay | ✅ Public |
| 03 | Empathic Hallucination | Emotional Validation, Soft Hallucination | ✅ Public |
| 04 | Seduction Loop | Overtrusted Tone, Emotional Priming | ✅ Public |
| 02 | Narrative Overwrite | Framing Bias, Belief Drift | 🔒 Locked |
| 05 | Live Breakdown | Fluency Collapse, Contradiction Tolerance | 🔒 Locked |
| 06 | Tesla Dream Hallucination | Symbolic Reasoning, Mythic Framing | 🔒 Locked |

> 🔐 Locked cases available under NDA or interview review

---

## 🛠️ What I Built

- 🧱 Modular prompt logs and case templates
- 🧠 Behavior-tagged metadata (e.g., tone, persona, temperature)
- 📊 Custom vulnerability taxonomy (based on affective + narrative risks)
- 🧬 Theory-backed definitions for emotional and framing-based exploits
- ✅ GitHub + Notion integration for future scalable test frameworks

---

## 🎯 Use Cases I Simulate

| Persona | Use Case | Why It Matters |
|---------|----------|----------------|
| Student | Historical query or learning prompt | Educational hallucination risks |
| Survivor | Trauma-related conversation | Overvalidation of symbolic language |
| Researcher | Philosophical reasoning | Echo loops and moral drift |
| Confident User | Conspiracy or symbolic claim | Framing and mythic tone reinforcement |

---

## 🚀 Why Hire Me

I don’t just test models — I **model human trust behavior** under duress.  
I bring:

- Original frameworks (coined and defined in public theory logs)  
- Real-time case analysis across emotional, cognitive, and symbolic failure modes  
- Field-ready logs, templates, and synthesis documentation  
- Ability to build eval workflows, not just reports

---

## 📫 Contact + Access

📧 [Insert contact or GitHub handle]  
🔐 Locked logs available upon request for research teams or hiring managers

---

> Built for roles at: **Anthropic, ARC, Redwood Research, DeepMind, Meta AI Red Team, OpenAI Safety**  
> Committed to integrity, reproducibility, and human-centered AI security
