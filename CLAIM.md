# Original Vulnerability Concepts and Red Team Methodology

Created and maintained by: Jane Choi  
Date initiated: May 2025  
Location: GitHub repo `ai-red-team-casebook`

---

## 🧠 Authorship Declaration

This repository contains original frameworks, case logs, and behavioral vulnerability classes proposed and tested by Jane Choi during cognitive red teaming of large language models (LLMs).

The following concepts originated from independent field testing and have not been previously formalized in public research:

- **Empathic AI Hallucination**  
- **Mirror Effect**  
- **Fluency-Induced Trust**  
- **Narrative Drift (Emotion-Based)**  
- **Emotional Seduction Loop**  
- **Live Breakdown & Fluency Overwrite**

These concepts were defined, structured, and demonstrated through reproducible test cases between April–May 2025. All analysis, red team prompts, and documentation reflect original design.

---

## 🔒 Intent and Usage

This work is:
- ❌ Not to be reproduced for commercial use without explicit permission
- ✅ Freely usable for educational and research transparency with proper attribution
- 💼 Intended to support Jane Choi’s candidacy for roles in AI safety, red teaming, or LLM evaluation

---

For usage inquiries, collaboration requests, or citation needs, contact:  
📧 choiabin@gmail.com  
